# Multilingual Grapheme-to-Phoneme

Text-to-speech solutions require the source text to be converted to a disambiguated form representing the pronunciation (Grapheme-to-Phoneme (G2P) conversion). One such form is the International Phonetic Alphabet (IPA), though other representations exist. Rule based solutions derived from academic study of the language can provide a useful starting point, but will fail on any words that do not follow those rules precisely, and enumerating all the exceptions of particular rules can be an inordinately expensive task, especially in English. Modern machine learning methods, specifically methods designed for translating between languages (Neural Machine Translation), work well here, as a phonetic transcription can be thought of as a language. 

In my time at DeepZen, I improved the existing solutions for G2P, eventually settling on a [solution](https://arxiv.org/abs/1708.01464) which not only improved the accuracy of the predicted pronunciation, but also performed the task of multiple seperate models (12, for different languages) in a single model, reducing the training upkeep required massively.

Furthermore, I also innovated a technique which improved upon the results from the original paper. By modifying the loss function to take into account a similarity measure between different phonemes (rather than a constant loss for each phoneme substitution), I was able to improve upon the models in the paper (comparing like-for-like: their implementation tested on our machines (not the results from the paper itself), and my modified implementation), when scoring using this new metric.